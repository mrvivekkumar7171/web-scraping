# ğŸ•¸ï¸ Web Scraping Projects Repository

This repository contains a collection of web scraping demos, projects and resources, designed to help you learn and apply web scraping techniques effectively. The projects cover a variety of real-world scenarios, ranging from financial data scraping to real estate listings and sports statistics.

---

## ğŸ“‚ Repository Contents

### 1. ğŸ““ Web Scraping Notes & Demos  - Jupyter Notebook
- Comprehensive Jupyter Notebook containing:
  - Web Scraping
  - Client-Server model/architecture
  - Anaconda
  - Selenium demo
  - Libraries: `requests`, `BeautifulSoup`, `Selenium`, `Pandas`
  - Step-by-step demo codes and explanations

### 2. ğŸ“ˆ Most Active Stocks Scraper from **[Yahoo Finance](https://finance.yahoo.com/)**
- Scrapes **Most Active Stocks** data from Yahoo Finance.
- Extracts:
  - Stock Symbol
  - Company Name
  - Price in $
  - Volume in Millions
  - Change
  - Market Cap in Billions
  - PE Ratio
- Useful for stocks trend analysis and dataset creation.
- Outputs data in CSV/JSON/XLSX format for analysis.

### 3. ğŸ  Real Estate Web Scraping from  **[99acres.com](https://www.99acres.com/)**
- Scrapes property listings from 99acres.com for the Gurugram region.
- Extracts:
  - Name
  - Price in â‚¹
  - Location (Gurugram)
  - Number of Bedrooms (bhk)
  - Area (sq. ft.)
- Useful for property trend analysis and dataset creation.
- Outputs data in CSV/JSON/XLSX format for analysis.

### 4. âš½ Top Scorers Scraper from **[BBC Sports Footbal](https://www.bbc.com/sport/football/premier-league/top-scorers)**
- Scrapes **Top Scorers** data from the BBC Sports Football section.
- Extracts:
  - Player Name
  - Goals Scored
  - Team Name
  - Matches
  - Assists
  - Shots
- Ideal for football enthusiasts and sports analysts.
- Outputs data in CSV/JSON/XLSX format for analysis.

---

## ğŸš€ Tech Stack
- **Python**
- **Jupyter Notebook**
- **BeautifulSoup**
- **Requests**
- **Selenium**
- **Pandas**
- **Numpy**

---

## ğŸ“Œ Usage

1. **Clone the Repository:**
```bash
git clone https://github.com/mrvivekkumar7171/web_scraping.git
cd web_scraping
```

2. **Install Dependencies:**
```bash
pip install -r requirements.txt
```

3. **Run Projects:**
- Open the Jupyter Notebook for notes and demos.
- Run individual scraping scripts as per your needs.

---

## ğŸ“„ License
This project is licensed under the MIT License.

---

## ğŸ™Œ Contributions
Feel free to contribute by opening issues or submitting pull requests!

---

**Happy Scraping! ğŸ•·ï¸**
